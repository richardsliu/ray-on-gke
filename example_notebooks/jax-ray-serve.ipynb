{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a35dc8-3950-464a-9103-b54918075100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray==2.3 in /opt/conda/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (23.1.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (8.1.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (3.12.2)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (4.17.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (1.0.5)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (4.21.12)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (6.0)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (1.3.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (2.31.0)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (20.23.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (23.1)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (1.51.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.3) (1.24.3)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.0.24->ray==2.3) (0.3.6)\n",
      "Requirement already satisfied: platformdirs<4,>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.0.24->ray==2.3) (3.5.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.3) (0.19.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.3) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.3) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.3) (2023.5.7)\n",
      "Requirement already satisfied: ray[serve] in /opt/conda/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (23.1.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (8.1.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (3.12.2)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (4.17.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (1.0.5)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (4.21.12)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (6.0)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (1.3.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (2.31.0)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (20.23.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (23.1)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (1.51.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (1.24.3)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (0.22.0)\n",
      "Requirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (6.3.0)\n",
      "Requirement already satisfied: aiohttp-cors in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (0.7.0)\n",
      "Requirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (0.5.5)\n",
      "Requirement already satisfied: aiorwlock in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (1.3.0)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (1.10.10)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (0.96.0)\n",
      "Requirement already satisfied: gpustat>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (1.1)\n",
      "Requirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (0.11.2)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (0.17.0)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (0.3.14)\n",
      "Requirement already satisfied: starlette in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (0.27.0)\n",
      "Requirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray[serve]) (3.7.4.post0)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[serve]) (4.0.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[serve]) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[serve]) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[serve]) (1.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[serve]) (4.6.2)\n",
      "Requirement already satisfied: nvidia-ml-py>=11.450.129 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[serve]) (11.525.112)\n",
      "Requirement already satisfied: psutil>=5.6.0 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[serve]) (5.9.5)\n",
      "Requirement already satisfied: blessed>=1.17.1 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[serve]) (1.20.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.0.24->ray[serve]) (0.3.6)\n",
      "Requirement already satisfied: platformdirs<4,>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.0.24->ray[serve]) (3.5.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette->ray[serve]) (3.6.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[serve]) (0.19.3)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[serve]) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[serve]) (2.11.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray[serve]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray[serve]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray[serve]) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray[serve]) (2023.5.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->ray[serve]) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->ray[serve]) (1.3.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[serve]) (0.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[serve]) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (1.59.1)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (2.17.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[serve]) (0.4.8)\n",
      "\u001b[31mERROR: Invalid requirement: 'fastapi=0.96'\n",
      "Hint: = is not a valid operator. Did you mean == ?\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ray==2.3\n",
    "!pip install ray[serve]\n",
    "!pip install fastapi==0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbb35d8-32f9-41f8-a2d5-d71fd236e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import Response\n",
    "import ray\n",
    "from ray import serve\n",
    "from typing import Any, List, Mapping\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ad33e7-ab2b-4d89-956b-a0187db5e61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.9</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.3.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://10.120.0.3:8265\" target=\"_blank\">http://10.120.0.3:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "ClientContext(dashboard_url='10.120.0.3:8265', python_version='3.10.9', ray_version='2.3.0', ray_commit='cf7a56b4b0b648c324722df7c99c168e92ff0b45', protocol_version='2022-12-06', _num_clients=1, _context_to_restore=<ray.util.client._ClientContext object at 0x7fc124110520>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init(\n",
    "    address=\"ray://example-cluster-kuberay-head-svc:10001\",\n",
    "    runtime_env={\n",
    "        \"pip\": [\n",
    "            \"diffusers==0.7.2\",\n",
    "            \"transformers==4.24.0\",\n",
    "            \"flax\",\n",
    "          ##\"pip install 'jax[tpu]==0.4.11' -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\",\n",
    "            \"tensorboard-plugin-profile\",\n",
    "            \"tensorboard\",\n",
    "            \"ray[serve]\",\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec69eeb9-4257-40ee-a7e7-88da8ee3ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "\n",
    "@serve.deployment(num_replicas=1, route_prefix=\"/\")\n",
    "@serve.ingress(app)\n",
    "class APIIngress:\n",
    "  \"\"\"`APIIngress`, e.g. the request router.\n",
    "\n",
    "  Arguments:\n",
    "    diffusion_model_handle: The handle that we use to access the Diffusion\n",
    "      model server that actually runs on TPU hardware.\n",
    "\n",
    "  \"\"\"\n",
    "  def __init__(self, diffusion_model_handle) -> None:\n",
    "    self.handle = diffusion_model_handle\n",
    "\n",
    "  @serve.batch(batch_wait_timeout_s=10, max_batch_size=8)\n",
    "  async def batched_generate_handler(self, prompts: List[str]):\n",
    "    \"\"\"Sends a batch of prompts to the TPU model server.\n",
    "\n",
    "    This takes advantage of @serve.batch which is Ray Serve's built-in batching\n",
    "    mechanism.\n",
    "\n",
    "    We set `batch_wait_timeout_s`=10 and `max_batch_size`=8 which means that we\n",
    "    wait the minimum of 10s or the time it takes to retrieve 8 requests in a\n",
    "    batch to begin processing.\n",
    "\n",
    "    Args:\n",
    "      prompts: A list of input prompts\n",
    "\n",
    "    Returns:\n",
    "      A list of responses which contents are raw PNG.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Number of input prompts: \", len(prompts))\n",
    "    print(prompts)\n",
    "    assert len(prompts) <= 8, \"We should not have more than 8 prompts.\"\n",
    "\n",
    "    # Pad to 8 for now (unclear if this is necessary)\n",
    "    num_to_pad = 8 - len(prompts)\n",
    "    prompts += [\"\"] * num_to_pad\n",
    "\n",
    "    image_ref = await self.handle.generate.remote(prompts)\n",
    "    images = await image_ref\n",
    "\n",
    "    # Remove the padded responses.\n",
    "    images = images[:8 - num_to_pad]\n",
    "    results = []\n",
    "    for image in images:\n",
    "      file_stream = BytesIO()\n",
    "      image.save(file_stream, \"PNG\")\n",
    "      results.append(\n",
    "          Response(content=file_stream.getvalue(), media_type=\"image/png\"))\n",
    "    return results\n",
    "\n",
    "  @app.get(\n",
    "      \"/imagine\",\n",
    "      responses={200: {\"content\": {\"image/png\": {}}}},\n",
    "      response_class=Response,\n",
    "  )\n",
    "  async def generate(self, prompt: str):\n",
    "    \"\"\"Requests the generation of an individual prompt.\n",
    "\n",
    "    This implementation simply re-routes the requests to the batch handler.\n",
    "    @serve.batch will return to this function an individual response.\n",
    "\n",
    "    Note that we specify the endpoint (e.g. /imagine) through FastAPI.\n",
    "\n",
    "    Args:\n",
    "      prompt: An individual prompt.\n",
    "\n",
    "    Returns:\n",
    "      A Response.\n",
    "\n",
    "    \"\"\"\n",
    "    return await self.batched_generate_handler(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f986f93-84e9-4809-bd91-08dac4856b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(\n",
    "    ray_actor_options={\n",
    "        \"resources\": {\"google.com/tpu\": 4}\n",
    "    },\n",
    "  ##  autoscaling_config={\"min_replicas\": 1, \"max_replicas\": 4},\n",
    "    )\n",
    "class StableDiffusion:\n",
    "  \"\"\"FLAX Stable Diffusion Ray Serve deployment.\n",
    "\n",
    "  This is the actual model server that runs on the TPU host.\n",
    "\n",
    "  Notes:\n",
    "    - We use custom resources to label a TPU host (note the name will change\n",
    "      once Ray Cluster on TPUs are standardized..)\n",
    "    - We can define the number of minimum and maximum replicas to the\n",
    "      autoscaler.\n",
    "    - Autoscaler will not be functional in this version (as we're using\n",
    "      tpu_controller) but should be functional on single TPU hosts using\n",
    "      the Ray Cluster launcher path OR through Kuberay\n",
    "    - Regardless of the route, Autoscaling works based on the load.\n",
    "      Documentation (https://docs.ray.io/en/latest/serve/architecture.html#ray-serve-autoscaling)\n",
    "      specifies that it is based on the ServeHandle queue and in-flight queries\n",
    "      for scaling decisions (e.g. I need to dig deeper to better understand).\n",
    "    - This example \"only\" uses a single model, but we could start composing\n",
    "      multiple handles together if we wanted to ensemble, or direct from\n",
    "      one model server to another.\n",
    "    - I suspect this could work on multi host TPUs, but not with autoscaling.\n",
    "\n",
    "  Attributes:\n",
    "    run_with_profiler: Whether or not to run with the profiler. Note that\n",
    "      this saves the profile to the separate TPU VM.\n",
    "\n",
    "  \"\"\"\n",
    "  def __init__(self, run_with_profiler: bool = False):\n",
    "    from diffusers import FlaxStableDiffusionPipeline\n",
    "    from flax.jax_utils import replicate\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    from jax import pmap\n",
    "\n",
    "    model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "    \n",
    "    self.pipeline, params = FlaxStableDiffusionPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        revision=\"bf16\",\n",
    "        dtype=jnp.bfloat16)\n",
    "\n",
    "    self.p_params = replicate(params)\n",
    "    self.p_generate = pmap(self.pipeline._generate)\n",
    "    self._run_with_profiler = run_with_profiler\n",
    "    self._profiler_dir = \"/tmp/tensorboard\"\n",
    "\n",
    "  def generate(self, prompts: List[str]):\n",
    "    \"\"\"Generates a batch of images from Diffusion from a list of prompts.\n",
    "\n",
    "    Notes:\n",
    "      - One \"sharp edge\" is that we need to run imports within the function\n",
    "        as this function is what is called on the raylet. Outside imports\n",
    "        cannot be sent over Ray to the raylets.\n",
    "\n",
    "    Args:\n",
    "      prompts: a list of strings. Should be a factor of 4.\n",
    "\n",
    "    Returns:\n",
    "      A list of PIL Images.\n",
    "\n",
    "    \"\"\"\n",
    "    from flax.training.common_utils import shard\n",
    "    import jax\n",
    "    import time\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "\n",
    "    print(\"sanity check: \", jax.device_count())\n",
    "\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    rng = jax.random.split(rng, jax.device_count())\n",
    "\n",
    "    assert len(prompts), \"prompt parameter cannot be empty\"\n",
    "\n",
    "    print(\"Prompts: \", prompts)\n",
    "    prompt_ids = self.pipeline.prepare_inputs(prompts)\n",
    "    #print(\"Prompt IDs: \", prompt_ids)\n",
    "    prompt_ids = shard(prompt_ids)\n",
    "    print(\"Sharded prompt ids has shape:\", prompt_ids.shape)\n",
    "    if self._run_with_profiler:\n",
    "      jax.profiler.start_trace(self._profiler_dir)\n",
    "\n",
    "    time_start = time.time()\n",
    "    images = self.p_generate(prompt_ids, self.p_params, rng)\n",
    "    images = images.block_until_ready()\n",
    "    elapsed = time.time() - time_start\n",
    "    if self._run_with_profiler:\n",
    "      jax.profiler.stop_trace()\n",
    "\n",
    "    print(\"Inference time (in seconds): \", elapsed)\n",
    "    print(\"Shape of the predictions: \", images.shape)\n",
    "    images = images.reshape(\n",
    "        (images.shape[0] * images.shape[1],) + images.shape[-3:])\n",
    "    print(\"Shape of images afterwards: \", images.shape)\n",
    "    return self.pipeline.numpy_to_pil(np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68062ad6-c2b0-4a26-b580-e5b5c93faa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RayServeSyncHandle(deployment='APIIngress')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion_bound = StableDiffusion.bind()\n",
    "deployment = APIIngress.bind(diffusion_bound)\n",
    "serve.run(deployment, host=\"0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0adf28ab-c6c0-4bf1-ae94-11adbc74dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import multiprocessing\n",
    "import random\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23bc766e-9ff8-40dc-8b90-abe8eb8419a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request_and_receive_image(prompt: str):\n",
    "  \"\"\"Sends a single prompt request and returns the Image.\"\"\"\n",
    "  inputs = \"%20\".join(prompt.split(\" \"))\n",
    "  resp = requests.get(f\"http://example-cluster-kuberay-head-svc:8000/imagine?prompt={inputs}\")\n",
    "  return BytesIO(resp.content)\n",
    "\n",
    "\n",
    "def send_requests():\n",
    "  \"\"\"Sends a list of requests and processes the responses.\"\"\"\n",
    "  prompts = [\n",
    "      \"Labrador in the style of Hokusai\",\n",
    "      \"Painting of a squirrel skating in New York\",\n",
    "      \"HAL-9000 in the style of Van Gogh\",\n",
    "      \"Times Square under water, with fish and a dolphin swimming around\",\n",
    "      \"Ancient Roman fresco showing a man working on his laptop\",\n",
    "      \"Close-up photograph of young black woman against urban background, high quality, bokeh\",\n",
    "      \"Armchair in the shape of an avocado\",\n",
    "      \"Clown astronaut in space, with Earth in the background\",\n",
    "  ]\n",
    "  with multiprocessing.Pool(processes=len(prompts)) as p:\n",
    "    raw_images = p.map(send_request_and_receive_image, prompts)\n",
    "\n",
    "  images = [Image.open(raw_image) for raw_image in raw_images]\n",
    "\n",
    "  def image_grid(imgs, rows, cols):\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, img in enumerate(imgs):\n",
    "      grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "  grid = image_grid(images, 2, 4)\n",
    "  grid.save(f\"./diffusion_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc092b83-b995-4c19-8537-73e8e75a0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "send_requests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed450f7-cdc6-4ba8-83bc-2b971baf5323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
